---
title: "Como Uso Agentes de IA para Revisar Meus Pr√≥prios PRs Antes de Qualquer Pessoa"
date: 2026-02-09
description: "Um guia pr√°tico para configurar code review com IA usando a API do Claude e Git hooks para pegar bugs antes dos seus colegas."
tags: ["ai-agents", "code-review", "claude-api", "git-hooks", "automation"]
categories: ["AI Development"]
draft: false
---

M√™s passado, eu fiz push de um PR que parecia impec√°vel. C√≥digo limpo, testes passando, documenta√ß√£o atualizada. Meu colega encontrou uma race condition no tratamento de erros em 10 minutos de review. Foi constrangedor ‚Äî n√£o porque eu errei, mas porque era exatamente o tipo de bug que uma IA teria pego se eu tivesse pedido pra ela olhar.

Essa experi√™ncia me motivou a construir algo que agora uso em todo PR: um agente de IA que revisa meu c√≥digo antes mesmo de eu pedir review humano. Aqui est√° como montei, o que realmente funciona e onde ainda deixa a desejar.

## O Problema da Auto-Revis√£o

Todo mundo faz self-review antes de fazer push. A gente l√™ o diff, talvez roda localmente e se convence de que est√° pronto. Mas a real √©: nosso c√©rebro √© p√©ssimo em encontrar os pr√≥prios erros. A gente enxerga o que pretendia escrever, n√£o o que de fato escreveu.

Linters tradicionais e an√°lise est√°tica ajudam, mas n√£o pegam bugs sem√¢nticos ‚Äî aqueles em que o c√≥digo est√° sintaticamente correto mas logicamente errado. √â a√≠ que a IA brilha. Ela consegue raciocinar sobre a inten√ß√£o, identificar edge cases que voc√™ n√£o considerou e perguntar "espera, o que acontece se X for null aqui?"

## Meu Setup: Claude + Git Pre-Push Hook

Depois de testar v√°rias abordagens, decidi por um hook de pre-push no Git que chama a API do Claude. Por que pre-push e n√£o pre-commit? Porque eu quero commits r√°pidos durante o desenvolvimento, mas quero uma revis√£o completa antes do c√≥digo sair da minha m√°quina.

A arquitetura b√°sica:

1. O hook de pre-push dispara um script Python
2. O script extrai o diff dos commits sendo enviados
3. O diff + contexto vai para a API do Claude com um prompt de code review
4. O Claude retorna os achados, o script exibe
5. Eu decido se fa√ßo push mesmo assim ou corrijo os problemas

### O Hook de Pre-Push

Primeiro, crie `.git/hooks/pre-push`:

```bash
#!/bin/bash

# Get the commits being pushed
remote="$1"
url="$2"

while read local_ref local_sha remote_ref remote_sha
do
    if [ "$remote_sha" = "0000000000000000000000000000000000000000" ]; then
        # New branch, review all commits
        range="$local_sha"
    else
        # Existing branch, review new commits only
        range="$remote_sha..$local_sha"
    fi
    
    # Run the AI review
    python3 ~/.git-hooks/ai-review.py "$range"
    
    if [ $? -ne 0 ]; then
        echo "AI review found issues. Push anyway? (y/n)"
        read -r response
        if [ "$response" != "y" ]; then
            exit 1
        fi
    fi
done

exit 0
```

Torne execut√°vel: `chmod +x .git/hooks/pre-push`

### O Script Python de Review

Aqui est√° o core do `~/.git-hooks/ai-review.py`:

```python
#!/usr/bin/env python3
import subprocess
import sys
import os
from anthropic import Anthropic

def get_diff(commit_range):
    """Get the diff for the specified commit range."""
    result = subprocess.run(
        ["git", "diff", commit_range, "--", "*.py", "*.js", "*.ts", "*.go"],
        capture_output=True,
        text=True
    )
    return result.stdout

def get_commit_messages(commit_range):
    """Get commit messages for context."""
    result = subprocess.run(
        ["git", "log", commit_range, "--oneline"],
        capture_output=True,
        text=True
    )
    return result.stdout

def review_code(diff, commits):
    """Send code to Claude for review."""
    client = Anthropic()
    
    prompt = f"""You are a senior software engineer reviewing a pull request. 
Review the following code changes and identify:

1. **Bugs**: Logic errors, race conditions, null pointer issues
2. **Security**: Injection vulnerabilities, auth issues, data exposure
3. **Edge cases**: Unhandled scenarios that could cause failures
4. **Performance**: Obvious inefficiencies or scaling concerns

Be specific. Reference line numbers when possible. Skip style nitpicks‚Äîfocus on things that could break in production.

Commit messages:
{commits}

Code diff:
{diff}

If you find no significant issues, respond with "LGTM" only.
Otherwise, list each issue with severity (HIGH/MEDIUM/LOW)."""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.content[0].text

def main():
    if len(sys.argv) < 2:
        print("Usage: ai-review.py <commit-range>")
        sys.exit(1)
    
    commit_range = sys.argv[1]
    diff = get_diff(commit_range)
    
    if not diff.strip():
        print("No relevant changes to review.")
        sys.exit(0)
    
    # Limit diff size to avoid token limits
    if len(diff) > 50000:
        print("Diff too large for AI review, reviewing first 50KB...")
        diff = diff[:50000]
    
    commits = get_commit_messages(commit_range)
    
    print("\nü§ñ AI Code Review in progress...\n")
    result = review_code(diff, commits)
    
    print(result)
    print()
    
    if "LGTM" in result and len(result) < 20:
        sys.exit(0)
    else:
        # Found issues, return non-zero
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## Exemplo Real: Um Bug que o Claude Pegou

Duas semanas atr√°s, eu estava refatorando uma fun√ß√£o de processamento de pagamento. Aqui vai uma vers√£o simplificada do que escrevi:

```python
async def process_payment(user_id: str, amount: Decimal) -> PaymentResult:
    user = await get_user(user_id)
    if not user:
        raise UserNotFoundError(user_id)
    
    balance = await get_balance(user_id)
    if balance < amount:
        raise InsufficientFundsError(user_id, balance, amount)
    
    # Deduct and process
    await deduct_balance(user_id, amount)
    result = await payment_gateway.charge(user.payment_method, amount)
    
    if not result.success:
        # Refund on failure
        await add_balance(user_id, amount)
        raise PaymentFailedError(result.error)
    
    return result
```

Resposta do Claude:

> **HIGH: Race condition no tratamento de saldo**
> 
> Entre a verifica√ß√£o do saldo (linha 7) e a dedu√ß√£o (linha 11), outra requisi√ß√£o pode modificar o saldo. Em cen√°rios de alta concorr√™ncia, isso poderia permitir saques a descoberto.
> 
> Al√©m disso, se `payment_gateway.charge()` falhar DEPOIS de `deduct_balance()` ter sucesso, e o refund via `add_balance()` tamb√©m falhar, o usu√°rio perde dinheiro sem nenhum registro.
> 
> Recomenda√ß√£o: Usar uma transa√ß√£o no banco de dados com lock a n√≠vel de linha, ou implementar opera√ß√µes idempotentes com um ledger separado.

Esse √© exatamente o tipo de bug que passa nos testes unit√°rios mas explode em produ√ß√£o. Eu sabia sobre race conditions conceitualmente, mas no fluxo de escrever c√≥digo, simplesmente... deixei passar. A IA n√£o deixou.

## O Que Funciona Bem

Depois de tr√™s meses usando esse setup, aqui est√° onde o review por IA consistentemente agrega valor:

**Problemas de concorr√™ncia**: O Claude √© excelente em identificar race conditions, potencial de deadlock e locks faltando. Ele pensa em "o que acontece se duas requisi√ß√µes baterem aqui ao mesmo tempo?" de forma mais confi√°vel do que eu.

**Lacunas no tratamento de erros**: Ele pega casos de erro faltando, especialmente em c√≥digo ass√≠ncrono onde exce√ß√µes podem ser engolidas silenciosamente.

**Checks de null/undefined**: O cl√°ssico "mas e se isso for null?" que a gente esquece quando est√° focado no happy path.

**Seguran√ßa b√°sica**: SQL injection, XSS, secrets hardcoded ‚Äî ele pega o OWASP Top 10 de forma consistente.

## O Que N√£o Funciona (Ainda)

Review de c√≥digo por IA n√£o √© m√°gica. Aqui est√° onde deixa a desejar:

**Valida√ß√£o de l√≥gica de neg√≥cio**: O Claude n√£o sabe que "usu√°rios acima de 65 anos ganham 10% de desconto" √© uma regra de neg√≥cio no seu sistema. Ele n√£o consegue verificar se voc√™ implementou a l√≥gica certa, apenas se sua l√≥gica √© internamente consistente.

**Performance em escala**: Ele pode sinalizar um loop O(n¬≤), mas n√£o sabe que seu n √© sempre < 10 ou que isso roda uma vez por dia. Contexto importa.

**Falsos positivos**: √Äs vezes ele sinaliza coisas que s√£o intencionais. Eu estimo que cerca de 20% das preocupa√ß√µes dele s√£o situa√ß√µes de "na verdade, t√° certo porque..."

**Diffs grandes**: Limites de token significam que voc√™ n√£o consegue revisar um refactor de 2000 linhas de forma efetiva. Eu quebro PRs grandes manualmente pra isso.

## A Realidade dos Custos

Vamos falar de dinheiro. Usando o modelo Sonnet do Claude, um review t√≠pico de PR (diff de 500 linhas) custa cerca de $0.02-0.05. Com 10 PRs por dia, d√° aproximadamente $10-15/m√™s. Pelos bugs que ele pega? Vale muito a pena.

Se voc√™ est√° em um time, pode rodar isso como um servi√ßo compartilhado e dividir os custos. Ou usar apenas para caminhos cr√≠ticos ‚Äî processamento de pagamento, autentica√ß√£o, manipula√ß√£o de dados.

## Melhorando com o Tempo

Eu iterei bastante no prompt. Algumas dicas:

1. **Seja espec√≠fico sobre o que ignorar**: Adicionei "ignore nitpicks de estilo, formata√ß√£o e sugest√µes de nomes" pra reduzir o ru√≠do.

2. **Adicione contexto do repo**: Para codebases complexas, incluo uma breve descri√ß√£o da arquitetura no prompt.

3. **Acompanhe a precis√£o**: Mantenho um log simples de problemas encontrados vs falsos positivos. Quando a taxa de falsos positivos sobe, ajusto o prompt.

4. **Combine com review humano**: Isso n√£o substitui seus colegas. Torna o review deles mais r√°pido porque as coisas √≥bvias j√° foram pegas.

## Conclus√£o

Usar IA para revisar meus PRs antes do review humano se tornou um dos meus projetos de automa√ß√£o com maior ROI. A configura√ß√£o levou uma tarde, os custos s√£o insignificantes e ele pega bugs reais ‚Äî do tipo que chegaria ao code review ou, pior, √† produ√ß√£o.

O insight principal: IA √© melhor revisando c√≥digo do que escrevendo do zero. Ela n√£o consegue arquitetar seu sistema, mas com certeza consegue te avisar quando voc√™ esqueceu de tratar um null pointer no seu error path.

Se voc√™ ainda n√£o faz isso, comece com um hook de pre-push simples no seu repo mais cr√≠tico. Veja o que ele pega em uma semana. Aposto que voc√™ vai se surpreender.

---

*Tem uma abordagem diferente pra code review com IA? Encontrou ferramentas que funcionam melhor? Adoraria saber ‚Äî me procure no [LinkedIn](https://linkedin.com) ou [Twitter/X](https://twitter.com).*
